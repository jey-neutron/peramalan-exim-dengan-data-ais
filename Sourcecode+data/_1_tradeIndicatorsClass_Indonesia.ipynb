{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indikator perdagangan untuk pelabuhan Indonesia\n",
    "Chunk pertama memuat beberapa fungsi yang dibutuhkan dari library modul ```pyspark.sql```\n",
    "dan beberapa library pendukung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>65</td><td>application_1621874771809_0016</td><td>pyspark3</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-10-250-1-43.ec2.internal:20888/proxy/application_1621874771809_0016/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-10-250-1-229.ec2.internal:8042/node/containerlogs/container_1621874771809_0016_01_000001/livy\">Link</a></td><td>âœ”</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "import time                              #time  \n",
    "from datetime import datetime, timedelta #datetime\n",
    "import geomesa_pyspark                   #penghubung database, integrasi dengan Spark Py API utk akses data di GeoMesa\n",
    "# library dari pyspark.sql \n",
    "import pyspark.sql.functions as F        #sql\n",
    "from pyspark.sql import SparkSession     #sesi spark untuk akses database dan agar sql berfungsi\n",
    "from pyspark.sql.types import *          #list tipe data yg tersedia\n",
    "from pyspark.sql.window import Window    #fungsi window\n",
    "from pyspark.sql.functions import col,sum,lpad, expr,lag,lead,when,lit #fungsi untuk dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class aisTradeIndicators\n",
    "Class aisTradeIndicators berisi fungsi yg digunakan untuk koneksi ke data, load data, cleaning data dengan memfilter moving ships, dan mendapatkan beberapa indikator. Bounding box port Indonesia didefinisikan dengan menggunakan koordinat pusat pelabuhan/port tersebut kemudian diekspansi sehingga membentuk bounding box disekitarnya. Class ini dapat mengestimasi indikator terkait perdagangan internasional seperti:\n",
    "- Time in port               : menghitung lama waktu kapal di pelabuhan\n",
    "- Port traffic               : jumlah unik kapal yang masuk ke suatu pelabuhan\n",
    "- Number of visit            : jumlah kunjungan kapal di pelabuhan\n",
    "- Number of draught changes  : jumlah kapal yang mengalami perubahan draft di pelabuhan (terbagi menjadi 2, yaitu positif dan negatif)\n",
    "- Draught change sizes       : besar perubahan draft kapal yang terjadi di pelabuhan (terbagi menjadi 2 juga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aisTradeIndicators(object):\n",
    "    \n",
    "    def __init__(self, appName, feature, userName):\n",
    "        '''Inisialisasi program'''\n",
    "        self.appName = appName\n",
    "        self.feature = feature\n",
    "        self.userName = userName\n",
    "        return None \n",
    "    \n",
    "    def geomesaConfig(self):\n",
    "        '''Pengaturan untuk terhubung ke db'''\n",
    "        conf = geomesa_pyspark.configure(\n",
    "            jars=['/usr/lib/spark/jars/geomesa-hbase-spark-runtime_2.11-2.3.0.jar'],\n",
    "            packages=['geomesa_pyspark','pytz'],\n",
    "            spark_home='/usr/lib/spark/').\\\n",
    "            setAppName(self.appName)\n",
    "        self.geomesaConfig = conf\n",
    "\n",
    "    def sparkSession(self):\n",
    "        '''Sesi spark'''\n",
    "        spark = (SparkSession.builder.config(conf = self.geomesaConfig).getOrCreate())\n",
    "        self.spark = spark\n",
    "    \n",
    "    def getFilteredData(self, startDate, endDate, areaLatitude, areaLongitude):\n",
    "        '''Filter data AIS berdasarkan area bounding box, seperti wilayah, dan rentang waktu'''\n",
    "        params = {\n",
    "            \"hbase.zookeepers\": \"hbase.optix-ons-local:2181\",\n",
    "            \"hbase.catalog\": \"ons-historical\"\n",
    "        }\n",
    "        # terhubung ke geomesa\n",
    "        df =( self.spark.read.format(\"geomesa\").options(**params).option(\"geomesa.feature\", self.feature).load()  )\n",
    "        # rentang waktu\n",
    "        df = df.filter((F.col(\"dtg\") > F.unix_timestamp(F.lit(startDate)).cast('timestamp')) &\n",
    "                      (F.col(\"dtg\") < F.unix_timestamp(F.lit(endDate)).cast('timestamp')) )\n",
    "        # filter bounding box\n",
    "        filterExpr = \"st_contains(st_makeBBox({0},{1},{2},{3}),position)\".format(areaLongitude['lLim'],\n",
    "                                                                                 areaLatitude['lLim'],\n",
    "                                                                                 areaLongitude['uLim'],\n",
    "                                                                                 areaLatitude['uLim'])\n",
    "        # filter mmsi yang valid\n",
    "        df = df.filter(F.expr(filterExpr))\\\n",
    "               .filter((df[\"mmsi\"]>=100000000) & (df[\"mmsi\"]<=999999999) )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def pilih_data(self, pilihan):\n",
    "        '''Fungsi memilih rentang data (selama enam bulan) -> untuk memudahkan saja'''\n",
    "        if (pilihan == 1): start_date = \"2018-12-01 00:00:00\"; end_date = \"2019-07-01 00:00:00\"\n",
    "        elif (pilihan == 2): start_date = \"2019-07-01 00:00:00\"; end_date = \"2020-01-01 00:00:00\"\n",
    "        elif (pilihan == 3): start_date = \"2020-01-01 00:00:00\"; end_date = \"2020-07-01 00:00:00\"\n",
    "        elif (pilihan == 4): start_date = \"2020-07-01 00:00:00\"; end_date = \"2021-01-01 00:00:00\"\n",
    "        else: start_date = \"2020-09-01 00:00:00\"; end_date = \"2021-02-01 00:00:00\"\n",
    "            \n",
    "        print('Pilihan: ',pilihan)\n",
    "        print(\"Memilih data range {} hingga {}\".format(start_date,end_date))\n",
    "        # split nama rentang waktu\n",
    "        a = start_date.split('-')\n",
    "        nama_start_date = a[0]+a[1]\n",
    "        b = end_date.split('-')\n",
    "        nama_end_date = b[0]+b[1]\n",
    "        \n",
    "        return start_date, end_date, nama_start_date, nama_end_date\n",
    "    \n",
    "    def movingShips(self, df, latDiff, longDiff, desc=False, addCount = False):\n",
    "        '''Filter moving ships'''\n",
    "        # df group berdasarkan mmsi\n",
    "        dfMS = df.groupBy(\"mmsi\")\\\n",
    "              .agg(F.max(\"latitude\").alias(\"latMax\"), F.min(\"latitude\").alias(\"latMin\"),\n",
    "                   F.max(\"longitude\").alias(\"longMax\"), F.min(\"longitude\").alias(\"longMin\") )      \n",
    "        \n",
    "        # menghitung jarak tempuh dengan menggunakan selisih koordinat\n",
    "        dfMS = dfMS.withColumn('latDelta',  F.abs(dfMS[\"latMax\"] - dfMS[\"latMin\"]) )\\\n",
    "                 .withColumn('longDelta', F.abs(dfMS[\"longMax\"] - dfMS[\"longMin\"]) )#\\\n",
    "                 #.withColumn('delta', F.col('latDelta')+ F.col('longDelta'))\n",
    "        #dfMS = dfMS.filter ((dfMS.latDelta>latDiff) & (dfMS.longDelta>longDiff) & (dfMS.delta>sumDiff))\\\n",
    "        \n",
    "        ##\n",
    "        if desc:\n",
    "            d1 = dfMS.filter ((dfMS.latDelta>latDiff) | (dfMS.longDelta>longDiff) )\\\n",
    "                 .select('mmsi')\n",
    "            d2 = dfMS.filter ((dfMS.latDelta<=latDiff) | (dfMS.longDelta<=longDiff) )\\\n",
    "                 .select('mmsi')\n",
    "            return d1,d2\n",
    "        ##\n",
    "        \n",
    "        dfMS = dfMS.filter ((dfMS.latDelta>latDiff) | (dfMS.longDelta>longDiff) )\\\n",
    "                 .select('mmsi')\n",
    "        dfMS = dfMS.cache()\n",
    "            \n",
    "        if addCount == True:\n",
    "            self.countMS = dfMS.count()\n",
    "        \n",
    "        df = df.join(dfMS, on=\"mmsi\")\n",
    "        return df\n",
    "    \n",
    "    def definePortNo(self, df, portCoords):\n",
    "        '''Mendefinisikan bounding box port berdasarkan koordinat pusatnya'''\n",
    "        df = df.withColumn('inPortNo', F.lit('noPort'))\n",
    "        # ekspansi koordinat port\n",
    "        for i in portCoords:\n",
    "            expansion = i['expansion']\n",
    "            values = \"longitude>{0} AND longitude<{1} AND latitude>{2} AND latitude<{3}\".format(i['lon_dd'] - expansion, \n",
    "                                                                                                i['lon_dd'] + expansion, \n",
    "                                                                                                i['lat_dd'] - expansion, \n",
    "                                                                                                i['lat_dd'] + expansion)\n",
    "            #print(\"Used rectangle for {0}: {1}\".format(i['name'], values))\n",
    "            df = df.withColumn(i['no'], F.expr(values))\n",
    "            # id port sesuaiin sama dataframe port\n",
    "            df = df.withColumn(\"inPortNo\", F.when(df[i['no']] == 'true', i['no']).otherwise(F.col(\"inPortNo\")))\n",
    "            df = df.drop(i['no'])\n",
    "        return df\n",
    "    \n",
    "    def absoluteMonth(self, df):\n",
    "        '''Membuat bulan absolut -> membuat bulan unik'''\n",
    "        df = df.withColumn('mYear', F.year('dtg'))\\\n",
    "                .withColumn('mMonthM',F.month('dtg'))\n",
    "        df = df.withColumn('mMonthAbs', F.col('mMonthM')+12*F.col('mYear'))\n",
    "        return df\n",
    "    \n",
    "    def cnt_cond(self, cond):\n",
    "        '''Fungsi menghitung data sesuai kondisi'''\n",
    "        #cnt_cond = lambda cond: F.sum(F.when(cond, 1).otherwise(0))\n",
    "        return F.sum(F.when(cond,1).otherwise(0))\n",
    "    \n",
    "    ######################\n",
    "    # INDIKATOR\n",
    "    #####################\n",
    "    \n",
    "    def timeDiffNextPort(self, df):\n",
    "        '''Menghitung waktu kapal di suatu port (ini subfungsi untuk menghitung indikator Time in Port)'''\n",
    "        # window partisi berdasarkan mmsi dan waktu\n",
    "        windowSpec1 = Window.partitionBy(\"mmsi\").orderBy(\"dtg\").rowsBetween(1,1)\n",
    "        # menghitung selisih waktu\n",
    "        df = df.withColumn(\"time_diff_next\",(F.unix_timestamp(F.lead(df.dtg,1).over(windowSpec1))-F.unix_timestamp(df.dtg)))\n",
    "        # jika destinasi sekarang sama dengan destinasi selanjutnya, maka diberi 0 saja\n",
    "        new_col1 = F.expr(\"\"\" IF ( inPortNo = next_inPortNo , time_diff_next, 0) \"\"\")     \n",
    "        # membuat kolom destinasi port selanjutnya dan selisih waktu yang telah dihitung tadi\n",
    "        df =  df.withColumn('next_inPortNo', F.lead(df.inPortNo, 1).over(windowSpec1))\\\n",
    "                .withColumn('time_diff_next_adj', new_col1)\\\n",
    "                .drop('time_diff_next')\n",
    "        return df\n",
    "    \n",
    "    def timeInPort(self, df, filter_anchmoor, pivot = False, filter_3days=False):\n",
    "        '''Menghitung waktu kapal di pelabuhan'''\n",
    "        # filter kapal yang anchor atau moor\n",
    "        if filter_anchmoor:\n",
    "            df = df.filter(df.nav_status.contains('Moored|Anchor') | (df.sog.astype('float') < 0.5 ))\n",
    "        # filter kapal yang kurang dari 3 hari di pelabuhan\n",
    "        if filter_3days:\n",
    "            df = df.filter(df.time_diff_next_adj<259200)\n",
    "            \n",
    "        # menghitung indikator; juga dihitung berdasarkan tipe kapal\n",
    "        df = df.withColumn('Cargo', F.when(F.col('vessel_type').contains('Cargo'), F.col('time_diff_next_adj')).otherwise(0) )\\\n",
    "            .withColumn('Tanker', F.when(F.col('vessel_type').contains('Tanker'), F.col('time_diff_next_adj')).otherwise(0) )\\\n",
    "            .groupby([\"inPortNo\",\"mMonthAbs\"])\\\n",
    "            .agg( # agregasi data ke pelabuhan dengan menjumlahkan seluruh waktu kapal di pelabuhan tsb\n",
    "                F.sum(\"time_diff_next_adj\").alias(\"portTimeTotal\"),\n",
    "                F.sum('Cargo').alias('portTimeTotalCargo'),\n",
    "                F.sum('Tanker').alias('portTimeTotalTanker')\n",
    "            ).sort([\"inPortNo\",\"mMonthAbs\"])\n",
    "        \n",
    "        if pivot == True:\n",
    "            df = df.groupBy(\"mMonthAbs\").pivot(\"inPortNo\").sum(\"portTimeTotal\")\n",
    "        return df\n",
    "    \n",
    "    def portTraffic(self, df, filter_anchmoor = False, pivot = False):\n",
    "        '''Jumlah unik kapal yang masuk ke pelabuhan'''\n",
    "        # filter kapal yang anchor atau moor\n",
    "        if filter_anchmoor:\n",
    "            df = df.filter(df.nav_status.contains('Moored|Anchor') | (df.sog.astype('float') < 0.5 ))\n",
    "        # menghitung indikator\n",
    "        df = df.withColumn('Cargo', F.when(F.col('vessel_type').contains('Cargo'), F.col('mmsi')).otherwise(None) )\\\n",
    "            .withColumn('Tanker', F.when(F.col('vessel_type').contains('Tanker'), F.col('mmsi')).otherwise(None) )\\\n",
    "            .groupBy(\"inPortNo\",\"mMonthAbs\")\\\n",
    "            .agg(\n",
    "                F.countDistinct(\"mmsi\").alias(\"totalTraffic\"),\n",
    "                F.countDistinct(\"Cargo\").alias(\"totalTrafficCargo\"),\n",
    "                F.countDistinct(\"Tanker\").alias(\"totalTrafficTanker\")\n",
    "            )\n",
    "        \n",
    "        if pivot == True:\n",
    "            df = df.groupBy(\"mMonthAbs\").pivot(\"inPortNo\").sum(\"totalTraffic\")\n",
    "        return df\n",
    "    \n",
    "    def numVisit(self, df, exim, filter_anchmoor = False):\n",
    "        '''Menghitung jumlah kunjungan kapal yang masuk ke pelabuhan'''\n",
    "        # filter kapal yang anchor atau moor\n",
    "        if filter_anchmoor:\n",
    "            df = df.filter(df.nav_status.contains('Moored|Anchor') | (df.sog.astype('float') < 0.5 ))\n",
    "        # jika tujuan sekarang sama dengan tujuan selanjutnya, maka tidak dihitung\n",
    "        if exim == 'EX':\n",
    "            expr = F.expr(\"\"\" IF ( inPortNo=next_inPortNo OR inPortNo='noPort', 0, 1) \"\"\")\n",
    "        else:\n",
    "            expr = F.expr(\"\"\" IF ( inPortNo=next_inPortNo OR next_inPortNo='noPort', 0, 1) \"\"\")\n",
    "        # drop data yang tujuan selanjutnya NA\n",
    "        df = df.na.drop(subset=[\"next_inPortNo\"])\n",
    "        # menghitung indikator\n",
    "        df = df.withColumn('numVisit', expr)\n",
    "        df = df.filter(df.numVisit == 1)\\\n",
    "            .groupby(['next_inPortNo','mMonthAbs'])\\\n",
    "            .agg(\n",
    "                F.count(F.lit(1)).alias('numVisit'),\n",
    "                self.cnt_cond(F.col('vessel_type').contains('Cargo')).alias('numVisitCargo'),\n",
    "                self.cnt_cond(F.col('vessel_type').contains('Tanker')).alias('numVisitTanker')\n",
    "            )\n",
    "        df = df.selectExpr(\"next_inPortNo as inPortNo\", \"mMonthAbs\", \"numVisit\", \"numVisitCargo\",\"numVisitTanker\")\n",
    "        return df\n",
    "    \n",
    "    def draughtDiff(self, df, tipe, filter_anchmoor = False, vessel_type=''):\n",
    "        '''Menghitung perbedaan draft yang terjadi pada kapal'''\n",
    "        # filter kapal yang anchor atau moor\n",
    "        if filter_anchmoor:\n",
    "            df = df.filter(df.nav_status.contains('Moored|Anchor') | (df.sog.astype('float') < 0.5 ))\n",
    "        # filter kapal berdasarkan tipenya\n",
    "        if vessel_type!='':\n",
    "            df = df.filter(df.vessel_type.contains(vessel_type))\n",
    "        # partisi by mmsi dan waktu\n",
    "        windowSpec1 = Window.partitionBy(\"mmsi\").orderBy(\"dtg\").rowsBetween(1,1)\n",
    "        df = df.withColumn(\"diff_draught_next\",(F.lead(df.draught,1).over(windowSpec1)-df.draught))\n",
    "        #grup by mmsi, melihat per mmsi nambah atau ngurang draughtnya\n",
    "        df = df.groupby(['mmsi','inPortNo','mMonthAbs'])\\\n",
    "            .agg(\n",
    "                F.sum('diff_draught_next').alias('diff_draught')\n",
    "            )\n",
    "        #split menjadi perubahan draft yang positif dan negatif\n",
    "        if(tipe == 'sum'): col_draughtDiff = F.sum('diff_draught').alias('draughtDiff')\n",
    "        elif (tipe == 'count'): col_draughtDiff = F.count(F.lit(1)).alias('draughtDiff')\n",
    "        df_pos = df.filter(F.col('diff_draught')>0).groupby(['inPortNo','mMonthAbs'])\\\n",
    "                .agg(\n",
    "                    #F.sum('diff_draught').alias('draughtDiff')\n",
    "                    col_draughtDiff\n",
    "                )\n",
    "        df_neg = df.filter(F.col('diff_draught')<0)\\\n",
    "                .withColumn('diff_draught', F.abs(df.diff_draught))\\\n",
    "                .groupby(['inPortNo','mMonthAbs'])\\\n",
    "                .agg(\n",
    "                    #F.sum('diff_draught').alias('draughtDiff')\n",
    "                    col_draughtDiff\n",
    "                )\n",
    "        return df_pos, df_neg\n",
    "    \n",
    "    def periodCalculation(self, df, mMonthAbs):\n",
    "        df = df.withColumn('yearMonth', F.col(mMonthAbs)/12)\\\n",
    "                .withColumn('year', F.floor('yearMonth'))\\\n",
    "                .withColumn('month', F.round((F.col('yearMonth') - F.col('year')) * 12, 0).cast('integer'))\\\n",
    "                .withColumn('period', F.when(F.col('month') < 10, F.concat(F.col('year'), F.lit('0'), F.col('month'))).otherwise(F.concat(F.col('year'), F.col('month')))) \\\n",
    "                .drop('yearMonth', 'year', 'month', mMonthAbs)\n",
    "        return df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set pengaturan geomesa dan mulai sesi Spark\n",
    "Pertama menginisiasi class aisTradeIndicators dengan nama dan username. Kemudian sumber data yang digunakan adalah data dari exactEarth.\n",
    "\n",
    "Fungsi geomesaConfig dan sparkSession sudah diatur di dalam class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aisClass = aisTradeIndicators(appName = 'IndoneAIS', feature = 'ee2', userName = 'jnickelson')\n",
    "aisClass.geomesaConfig()\n",
    "aisClass.sparkSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pilih range data\n",
    "Pilihan range data sementara dari 1 sampai 4, dengan masing-masing pilihan mempunyai range data 6 bulan. Range antara Desember 2018 sampai Desember 2020. Ini untuk memudahkan saja sih.\n",
    "\n",
    "Kemudian area yang dipakai adalah negara Indonesia dengan bounding box seperti di chunk bawah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pilihan:  2\n",
      "Memilih data range 2019-07-01 00:00:00 hingga 2020-01-01 00:00:00"
     ]
    }
   ],
   "source": [
    "pilihan = 2\n",
    "start_date, end_date, nama_start_date, nama_end_date = aisClass.pilih_data(pilihan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data berdasarkan range dan wilayah interest\n",
    "df = aisClass.getFilteredData(startDate = start_date, endDate = end_date, \n",
    "                              areaLatitude = {\"uLim\": 6.8391696263, \"lLim\": -10.5742220783}, \n",
    "                              areaLongitude = {\"uLim\": 141.064453125, \"lLim\": 94.482421875})\n",
    "# memfilter wilayah indo+3, untuk mendefinisikan kapal yang keluar masuk indo, maka difilter wilayah luar indo duls\n",
    "# indo 94.482421875 -10.5742220783 141.064453125 6.8391696263"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memilih variabel data AIS yang digunakan untuk menghasilkan indikator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[mmsi: bigint, dtg: timestamp, longitude: float, latitude: float, vessel_type: string, sog: double, nav_status: string, draught: double, length: int, width: int, flag_country: string, destination: string]"
     ]
    }
   ],
   "source": [
    "#tipe_vessel = 'Cargo|Tanker'\n",
    "df = df.select('mmsi','dtg','longitude','latitude','vessel_type','sog','nav_status','draught',\n",
    "               'length','width', 'flag_country','destination')\\\n",
    "    .withColumn('latitude', df['latitude'].cast('float'))\\\n",
    "    .withColumn('longitude', df['longitude'].cast('float'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memfilter data\n",
    "- Filtering moving ships:\n",
    "    Data AIS akan difilter hanya kapal yang bergerak/berlayar, karena yang dianggap berkontribusi terhadap perdagangan internasional. Kriteria kapal dianggap berlayar yaitu:\n",
    "    - Selisih perbedaan max dan min latitude lebih dari 0.1\n",
    "    - Selisih perbedaan max dan min longitude lebih dari 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df00 = df\n",
    "dfd = aisClass.movingShips(df = df, latDiff = 0.1, longDiff = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filter var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[mmsi: bigint, dtg: timestamp, longitude: float, latitude: float, vessel_type: string, sog: double, nav_status: string, draught: double, length: int, width: int, flag_country: string, destination: string]"
     ]
    }
   ],
   "source": [
    "#.filter(df.vessel_type.rlike('Cargo|Tanker'))\\\n",
    "dfd = df\\\n",
    "    .filter(df.nav_status.rlike('Moored|Anchor|Manoeuvrability'))\\\n",
    "    .filter(df.draught > 0)\n",
    "dfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mendefinisikan port\n",
    "\n",
    "Data AIS akan difilter berdasarkan area pelabuhan di Indonesia. Data pelabuhan didapat dalam file ```port.csv``` yang memuat id, nama, dan koordinatnya. Bounding box akan dipakai dengan ekspansi sebesar 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get port coords from file\n",
    "portCoords = spark.read.csv('s3://optix.ons.jupyter/jupyter/jnickelson/port.csv', header=True)\n",
    "portCoords = portCoords.select('no','name','lat_dd','lon_dd')\\\n",
    "            .withColumn('expansion', F.lit(0.3))\\\n",
    "            .withColumn('lat_dd', portCoords[\"lat_dd\"].cast('float'))\\\n",
    "            .withColumn('lon_dd', portCoords[\"lon_dd\"].cast('float'))\\\n",
    "            .collect() #take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[mmsi: bigint, dtg: timestamp, longitude: float, latitude: float, vessel_type: string, sog: double, nav_status: string, draught: double, length: int, width: int, flag_country: string, destination: string, inPortNo: string]"
     ]
    }
   ],
   "source": [
    "dfd1 = aisClass.definePortNo(df = dfd, portCoords = portCoords)\n",
    "dfd1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menghitung selisih waktu dan bulan absolut\n",
    "\n",
    "Selisih waktu kapal unik antar pelabuhan perlu dihitung. Definisi unik dari periode menggunakan fungsi absoluteMonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[mmsi: bigint, dtg: timestamp, longitude: float, latitude: float, vessel_type: string, sog: double, nav_status: string, draught: double, length: int, width: int, flag_country: string, destination: string, inPortNo: string, next_inPortNo: string, time_diff_next_adj: bigint, mYear: int, mMonthM: int, mMonthAbs: int]"
     ]
    }
   ],
   "source": [
    "dfd2 = aisClass.timeDiffNextPort(df = dfd1)\n",
    "dfd2 = aisClass.absoluteMonth(df = dfd2)\n",
    "dfd2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "## Menghitung indikator\n",
    "\n",
    "Setiap indikator yang terbentuk diagregasi per port. Fungsi periodCalculation yang digunakan di chunk selanjutnya yaitu mengubah bulan absolut menjadi readable format sesuai periodenya. Fungsi time untuk menghitung waktu running program dan waktu mengekspor data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate time in port  \n",
    "Menghitung waktu yang dihabiskan kapal di pelabuhan, kemudian diagregasi per pelabuhan dengan menjumlahkan waktu setiap kapal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = aisClass.timeInPort(df = dfd2, pivot=False, filter_anchmoor = False, filter_3days=True)\n",
    "df1 = aisClass.periodCalculation(df = df1, mMonthAbs = 'mMonthAbs')\n",
    "#df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengekspor dataframe indikator yang terbentuk ke file akun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write data-2 time: 13.142455089092255 min"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df1.repartition(1)\\\n",
    "   .write.csv(\"s3://optix.ons.jupyter/jupyter/jnickelson/extract/new/timeInPort_{}_{}.csv\".format(\n",
    "    nama_start_date,nama_end_date), header = True)\n",
    "print(\"Write data-{} time: {} min\".format(pilihan, (time.time()-start_time)/60) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate port traffic\n",
    "\n",
    "Menghitung jumlah unik kapal yang masuk atau berada di pelabuhan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = aisClass.portTraffic(df = dfd2, pivot=False, filter_anchmoor=False)\n",
    "df2 = aisClass.periodCalculation(df = df2, mMonthAbs = 'mMonthAbs')\n",
    "#df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write data-2 time: 13.964130055904388 min"
     ]
    }
   ],
   "source": [
    "# Mengekspor dataframe indikator yang terbentuk ke file akun\n",
    "start_time = time.time()\n",
    "df2.repartition(1)\\\n",
    "   .write.csv(\"s3://optix.ons.jupyter/jupyter/jnickelson/extract/new/portTraffic_{}_{}.csv\".format(\n",
    "    nama_start_date,nama_end_date), header = True)\n",
    "print(\"Write data-{} time: {} min\".format(pilihan, (time.time()-start_time)/60) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate number visit\n",
    "Menghitung jumlah kunjungan kapal yang masuk ke pelabuhan"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "exim = 'EX' if dest_bin=='nonID' else 'IM'\n",
    "exim, dest_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = aisClass.numVisit(df = dfd2, exim='IM', filter_anchmoor = False)\n",
    "df4 = aisClass.periodCalculation(df = df4, mMonthAbs = 'mMonthAbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write data-2 time: 6.359950264294942 min"
     ]
    }
   ],
   "source": [
    "# Mengekspor dataframe indikator yang terbentuk ke file akun\n",
    "start_time = time.time()\n",
    "df4.repartition(1)\\\n",
    "   .write.csv(\"s3://optix.ons.jupyter/jupyter/jnickelson/extract/new/numVisit_{}_{}.csv\".format(\n",
    "    nama_start_date,nama_end_date), header = True)\n",
    "print(\"Write data-{} time: {} min\".format(pilihan, (time.time()-start_time)/60) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate difference draught"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fanchmoor = False\n",
    "tipe = 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchmoor =  False\n",
      "Tipe =  count"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "#def draughtDiff(self, df, filter_anchmoor, vessel_type):\n",
    "df5_pos, df5_neg = aisClass.draughtDiff(dfd2, filter_anchmoor = fanchmoor, tipe='count')\n",
    "df5c_pos, df5c_neg = aisClass.draughtDiff(dfd2, filter_anchmoor = fanchmoor, vessel_type = 'Cargo', tipe=tipe) \n",
    "df5t_pos, df5t_neg = aisClass.draughtDiff(dfd2, filter_anchmoor = fanchmoor, vessel_type = 'Tanker', tipe=tipe) \n",
    "#merge pos\n",
    "dfs = [df5_pos, df5c_pos, df5t_pos]\n",
    "dfs_renamed = [df.selectExpr('inPortNo', 'mMonthAbs', 'draughtDiff as draughtDiff{}'.format(i)) for i, df in enumerate(dfs)]\n",
    "df5all_pos = reduce(lambda x, y: x.join(y, ['inPortNo', 'mMonthAbs'], how='outer'), dfs_renamed)\\\n",
    "            .selectExpr('inPortNo', 'mMonthAbs', 'draughtDiff0 as draughtDiff',\n",
    "                        'draughtDiff1 as draughtDiffCargo', 'draughtDiff2 as draughtDiffTanker')\n",
    "df5all_pos = aisClass.periodCalculation(df = df5all_pos, mMonthAbs = 'mMonthAbs')\n",
    "#merge neg\n",
    "dfs = [df5_neg, df5c_neg, df5t_neg]\n",
    "dfs_renamed = [df.selectExpr('inPortNo', 'mMonthAbs', 'draughtDiff as draughtDiff{}'.format(i)) for i, df in enumerate(dfs)]\n",
    "df5all_neg = reduce(lambda x, y: x.join(y, ['inPortNo', 'mMonthAbs'], how='outer'), dfs_renamed)\\\n",
    "            .selectExpr('inPortNo', 'mMonthAbs', 'draughtDiff0 as draughtDiff',\n",
    "                        'draughtDiff1 as draughtDiffCargo', 'draughtDiff2 as draughtDiffTanker')\n",
    "df5all_neg = aisClass.periodCalculation(df = df5all_neg, mMonthAbs = 'mMonthAbs')\n",
    "\n",
    "print('Anchmoor = ',fanch)\n",
    "print('Tipe = ', tipe)\n",
    "#df5all_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write pos data-2 time: 15.050783908367157 min"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df5all_pos.repartition(1)\\\n",
    "   .write.csv(\"s3://optix.ons.jupyter/jupyter/jnickelson/extract/new/draughtDiff_pos{}_{}_{}.csv\".format(tipe, nama_start_date,nama_end_date),\n",
    "              header = True)\n",
    "print(\"Write pos data-{} time: {} min\".format(pilihan, (time.time()-start_time)/60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write neg data-2 time: 15.106862819194793 min"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df5all_neg.repartition(1)\\\n",
    "   .write.csv(\"s3://optix.ons.jupyter/jupyter/jnickelson/extract/new/draughtDiff_neg{}_{}_{}.csv\".format(tipe, nama_start_date,nama_end_date),\n",
    "              header = True)\n",
    "print(\"Write neg data-{} time: {} min\".format(pilihan, (time.time()-start_time)/60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchmoor =  False\n",
      "Tipe =  sum"
     ]
    }
   ],
   "source": [
    "tipe = 'sum'\n",
    "from functools import reduce\n",
    "#def draughtDiff(self, df, filter_anchmoor, vessel_type):\n",
    "df5_pos, df5_neg = aisClass.draughtDiff(dfd2, filter_anchmoor = fanch, tipe='count')\n",
    "df5c_pos, df5c_neg = aisClass.draughtDiff(dfd2, filter_anchmoor = fanch, vessel_type = 'Cargo', tipe=tipe) \n",
    "df5t_pos, df5t_neg = aisClass.draughtDiff(dfd2, filter_anchmoor = fanch, vessel_type = 'Tanker', tipe=tipe) \n",
    "#merge pos\n",
    "dfs = [df5_pos, df5c_pos, df5t_pos]\n",
    "dfs_renamed = [df.selectExpr('inPortNo', 'mMonthAbs', 'draughtDiff as draughtDiff{}'.format(i)) for i, df in enumerate(dfs)]\n",
    "df5all_pos = reduce(lambda x, y: x.join(y, ['inPortNo', 'mMonthAbs'], how='outer'), dfs_renamed)\\\n",
    "            .selectExpr('inPortNo', 'mMonthAbs', 'draughtDiff0 as draughtDiff',\n",
    "                        'draughtDiff1 as draughtDiffCargo', 'draughtDiff2 as draughtDiffTanker')\n",
    "df5all_pos = aisClass.periodCalculation(df = df5all_pos, mMonthAbs = 'mMonthAbs')\n",
    "#merge neg\n",
    "dfs = [df5_neg, df5c_neg, df5t_neg]\n",
    "dfs_renamed = [df.selectExpr('inPortNo', 'mMonthAbs', 'draughtDiff as draughtDiff{}'.format(i)) for i, df in enumerate(dfs)]\n",
    "df5all_neg = reduce(lambda x, y: x.join(y, ['inPortNo', 'mMonthAbs'], how='outer'), dfs_renamed)\\\n",
    "            .selectExpr('inPortNo', 'mMonthAbs', 'draughtDiff0 as draughtDiff',\n",
    "                        'draughtDiff1 as draughtDiffCargo', 'draughtDiff2 as draughtDiffTanker')\n",
    "df5all_neg = aisClass.periodCalculation(df = df5all_neg, mMonthAbs = 'mMonthAbs')\n",
    "\n",
    "print('Anchmoor = ',fanch)\n",
    "print('Tipe = ', tipe)\n",
    "#df5all_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write pos data-2 time: 15.056995570659637 min"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df5all_pos.repartition(1)\\\n",
    "   .write.csv(\"s3://optix.ons.jupyter/jupyter/jnickelson/extract/new/draughtDiff_pos{}_{}_{}.csv\".format(tipe, nama_start_date,nama_end_date),\n",
    "              header = True)\n",
    "print(\"Write pos data-{} time: {} min\".format(pilihan, (time.time()-start_time)/60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write neg data-2 time: 16.574400250116984 min"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df5all_neg.repartition(1)\\\n",
    "   .write.csv(\"s3://optix.ons.jupyter/jupyter/jnickelson/extract/new/draughtDiff_neg{}_{}_{}.csv\".format(tipe, nama_start_date,nama_end_date),\n",
    "              header = True)\n",
    "print(\"Write neg data-{} time: {} min\".format(pilihan, (time.time()-start_time)/60) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selesai dan menghentikan sesi spark\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
